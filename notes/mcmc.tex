% Give example of Polya-Gamma augmentation scheme for logistic regression. The joint Gibbs sampler is easy because the prior is conjugate to the augmented target.

Maximizing expected utility requires computing integrals. 
Numerical integration consists in finding $T$ nodes $x_t$ and weights $w_t$, such
that
$$
{\mathcal{E}_T(f)} \triangleq  \int f(x)\d\mu(x)  - \quad \sum_{t=1}^T w_t f(x_t) = o_{T\rightarrow \infty}(1), \quad \forall
f:\mathbb{R}^d\rightarrow\mathbb{R}\in\mathcal C,
$$
where $\mathcal C$ is a large class of functions.
For any smooth $f$, Riemann-like (i.e., grid-based) integration leads to $\mathcal{E}_T(f) \sim \sqrt{d} T^{-1/d}$, so that grids become essentially useless beyond $d=3$.
Monte Carlo methods are randomized constructions of nodes and weights. 
Since $\mathcal{E}_T(f)$ is then random, statements on the error shall be with high probability, in expectation, about the asymtotic fluctuations, etc.

We shall see that Monte Carlo methods $(i)$ can accomodate settings where the target $\mu$ in \eqref{e:numerical_integration} is only available through the evaluation of a unnormalized density $\d\mu(x) = \pi(x)\d x = \pi_u(x)/Z\d x$, as is almost always the case in Bayesian learning; and that $(ii)$ some Monte Carlo methods have an error that scales only polynomially with the dimension of the support of the integrand.

\paragraph{References.} 
The reference book for basic Monte Carlo methods is \citep{RoCa04}. 
For theoretical results on MCMC, we refer to \citep[Chapters 5 to 7]{DoMoSt14}. 
For more recent methods, we shall refer to papers.
For demos of MCMC samplers, see \cfdemo.
Finally, we shall not cover deterministic alternatives to Monte Carlo methods in large dimension, see quasi-Monte Carlo methods \citep{DiPi10}.

\section{Basic Monte Carlo}

If we knew how to sample from $\pi$, we could take $x_t\sim\pi$ i.i.d., $w_t=1/T$.
Chebyshev's inequality would lead to
  $$ \mathbb{P}\left({\mathcal{E}_T(f)} \geq \alpha\frac{\sigma(f)}{\sqrt{T}} \right) \leq \frac{1}{\alpha^2}, \quad \forall \alpha>0,$$
  as soon as $\sigma(f)^2 := \mathbb{E}_{X\sim\pi} [f(X) - \int f(x)\pi(x)\d x]<+\infty$.

In practice, we never have access to a sampler of $\pi$, so we choose an instrumental distribution $q(x)\d x$, sample $x_t$ i.i.d. from $q$.
If we can evaluate $\pi$, then $w_t=\pi(x_t)/q(x_t)$ leads to an unbiased estimator called the \emph{importance sampling}.
Its error can also be controlled by the Chebyshev inequality. 
But more often than not, we can only evaluate an unnormalized density $\pi_u$. 
An alternative is to then set $w_t\propto \pi_u(x_t)/q(x_t)$ and normalize the weights so that $\sum_t w_t=1$. 
This leads to the \emph{self-normalized importance sampling estimator}
$$
\widehat I_T^\text{NIS} = \frac{\sum_{t=1}^T \frac{\pi_u(\theta_t)}{q(\theta_t)} f(x_t)}{\sum_{t=1}^T \frac{\pi_u(\theta_t)}{q(\theta_t)}} \rightarrow \frac{\int f(x)\pi_u(x)\d x}{\int \pi_u(x)\d x} = \int f(x)\pi(x)\d x,
$$
where the convergence is almost sure (apply the strong law of large numbers to both the numerator and the denominator).
\begin{proposition}[CLT for NIS] The NIS estimator satisfies
   $$
   \sqrt{T} \left (\widehat I_T^\text{NIS} - \int f(x)\pi(x)\d x\right ) \rightarrow_d \cN(0,\sigma_{\text{NIS}}^2(f))
   $$
   where $f$ is such that
   $$
   \sigma_{\text{NIS}}^2(f) \triangleq TBC <\infty.
   $$
\end{proposition}
\begin{proof}
    See exercise sheet. Hint: use the delta method.
\end{proof}
Unfortunately, while NIS does accomodate unnormalized targets, it does not solve the curse of dimensionality: even when $\pi$ and $q$ are both Gaussian, only with different covariance matrices, one can show that 
$$
\log \sigma_{\text{NIS}}^2(f) = \Theta(d).
$$

\section{The Metropolis-Hastings algorithm}
Metropolis-Hastings (MH) is the achetypal MCMC algorithm, and is still the main building block of modern MCMC algorithms. 
The idea is to take the nodes as the truncated history of a Markov chain $(X_t)$, which we build so as to guarantee that $\mathcal{E}_T(f)\rightarrow 0$.
To see how to build $(X_t)$, remember first the law of large numbers for Markov chains. 

\begin{proposition}[LLN for Markov chains; see e.g. \cite{DoMoSt14}]
    \label{p:lln_markov}
    Let $(X_t)_{t\in\mathbb N}$ be a Markov chain with Markov kernel $P$.
    If
    \begin{enumerate}
      \item There exists $\mu$ s.t. 
      $$
      \int \d\mu(x) P(x, B) = \mu(B).
      $$
      \item For any $A$ with $\mu(A)>0$, for any $\theta\in \Theta$,
      $$ 
      \mathbb{P}_{x} \left(\sum_{t=0}^\infty 1_{\theta_t\in A} = +\infty\right) = 1,
      $$
    \end{enumerate}
    then for any initial distribution $\mu_0$ of $X_0$, almost surely
    $$
    \frac{1}{T} \sum_{t=1}^T f(\theta_t) \rightarrow \int f\mathrm{d}\mu,
    $$
    where $f\in L^1(\mu)$. 
\end{proposition}
The first condition states that $\pi$ is an \emph{invariant distribution} of the chain: if $X_t\sim\mu$, then $X_{t+1}\sim\mu$. 
The second condition is called \emph{Harris recurrence}: starting from any $x$, i.e. $X_0\sim\delta_{x}$, then the chain returns an infinite number of times to $A$ almost surely, as soon as $A$ is charged by $\mu$. 
Intuitively, this makes sure that there is an infinity of nodes on $A$, so that the integral of $f$ on $A$ is accurately estimated.

The Metropolis-Hastings kernel \citep{MTTR50,Has73} is a Markov kernel that satisfies the assumptions of Proposition~\ref{p:lln_markov} with a user-specified limiting distribution $\pi$, all of that using only an unnormalized density of $\pi$.
The MH kernel reads
$$
    P_{\mathrm{MH}}(x,x') = \alpha(x,x') q(x'\vert x) + \delta_x(x')\left[1-\int \alpha( x,x') q(x'\vert x)\right]\d x',
$$
where, for each $x$, $q(\cdot\vert x)$ is a probability distribution, and
\begin{equation}
    \label{e:mh_acceptance_rate}
    \alpha(x,x') = 1\wedge \frac{\pi(x')}{\pi(x)} \frac{q(x\vert x')}{q(x'\vert x)}.
\end{equation}
\begin{lemma}
    $P_{\mathrm{MH}}$ leaves $\pi$ invariant.
\end{lemma}
\begin{proof}
    See exercise sheet. Hint: prove first detailed balance, i.e. 
    $$ 
        \pi(x) P_{\mathrm{MH}}(x,x') = \pi(x') P_{\mathrm{MH}}(x', x), \quad x, x'\in\cX,
    $$
    then integrate both sides.
\end{proof}
Note that \eqref{e:mh_acceptance_rate} is not the only way to satisfy detailed balance; see e.g. Barker's acceptance rate and Peskun's result on the optimality of the MH acceptance rate.

Now that we have shown that $\pi$ is left invariant, it remains to check Harris recurrence to get the LLN.
Intuitively, it is enough that the proposal distribution charges the whole space, so that there is a small chance to move anywhere in a single step.
Indeed, \cite{RoCa04} prove that if 
$$
    \pi(A)>0\Rightarrow (\forall x) q(A\vert x)>0, 
$$
then $P_{\text{MH}}$ satisfies the LLN.

\begin{example}[Logistic regression with pyMC]
\end{example}

\section{Gibbs sampling}
\label{s:gibbs_sampling}

While sampling from $\pi$ is not accessible in general, it is sometimes possible to sample from the conditionals of some components of $x$ given the rest of the components. 
Let $[d]$ be partitioned in $I_1, \dots, I_p$,
The MH kernel with proposal
$$
    q(\theta'\vert\theta) = \frac1p \sum_{k=1}^p \un{\pi(\theta'_{I_k}\vert \theta_{\setminus I_k})} 1_{\theta'_{\setminus I_k} = \theta_{\setminus I_k}}, \quad \theta_{\setminus I_k}:= (\theta_{I_1},\dots,\theta_{I_{k-1}},\theta_{I_{k+1}},\dots,\theta_{I_d}),
$$
has acceptance probability $1$. 
The algorithm that iteratively applies this MH kernel is called the (random scan) Gibbs sampler.

As an example of application, recall the LDA model of \cref{ex:lda}. 
This is a joint distribution for which we can easily derive the conditionals for the natural partition given by the names of the unobserved variables.
To derive them, we shall repeatedly use Bayes's theorem as well as the DAG structure.
We start with a general observation: if $x_A\perp x_B\vert x_C$ in a DAG, then 
\begin{equation}
    \label{e:conditional_independence}
    p(x_A\vert x_B, x_C) = \frac{p(x_A, x_B, x_C)}{p(x_B, x_C)} = \frac{p(x_A, x_B \vert x_C) p(x_C)}{p(x_B, x_C)} = \frac{p(x_A\vert x_C) p(x_B\vert x_C) p(x_C)}{{p(x_B\vert x_C)p(x_C)}} = p(x_A\vert x_C).
\end{equation}

\paragraph{The conditional of $\pi_i$} 
Fix a document index $i\in[N]$. 
Using \eqref{e:conditional_independence}, the conditional of $\pi_i$ given the rest in LDA is simply
$$ 
    \pi_i \vert \pi_{\setminus i}, \mathbf{z}, \mathbf{y}, B = \pi_i \vert z_{i:} \, .
$$
Now we recognize a conjugate model, the Dirichlet-categorical (see exercise sheet), so that 
$$
    \pi_i \vert z_{i:} \sim \mathrm{Dir}\left ((\alpha_k + \sum_{\ell=1}^{L_i} 1_{z_{i\ell}=k})_{k\in [K]} \right ).
$$

\paragraph{The conditional of $B_{k:}$}
Fix a topic index $k\in[K]$, then by \eqref{e:conditional_independence},
$$
    B_{k:} \vert \mathbf{\pi}, \mathbf{z}, \mathbf{y}, B_{\setminus k,:} \sim B_{k:} \vert \mathbf{z}, \mathbf{y}.
$$
Now a trained eye would recognize a Dirichlet-categorical conjugate situation again. 
Alternately, we can use Bayes' theorem and force terms to appear that we have specified in our model
\begin{align*}
    p(B \vert \mathbf{z}, \mathbf{y}) &\propto p(B, \mathbf{\pi}, \mathbf{z}, \mathbf{y})\\
    & = \un{p(\mathbf{y} \vert B, \mathbf{z})} p(\mathbf{z}\vert B) \unn{p(B)}.
\end{align*}
Note that $\mathbf{z}\perp B$ in the DAG, so that $p(\mathbf{z}\vert B) = p(\mathbf{z})$ is independent of $B$.
We thus obtain
\begin{align*}
    p(B \vert \mathbf{z}, \mathbf{y})
    &\propto \un{\prod_{i=1}^N \prod_{\ell=1}^{L_i} \prod_{k=1}^K B_{kv}^{1_{z_{i\ell}=k}1_{y_{i\ell}=v}}} \unn{\prod_{k=1}^K 1_{\Delta_V}(B_{k:}) \prod_{v=1}^V B_{kv}^{\gamma_v-1}}.\\
    &= \prod_{k=1}^K\left[ 1_{\Delta_V}(B_{k:}) \prod_{i=1}^N \prod_{\ell=1}^{L_i} B_{kv}^{1_{z_{i\ell}=k}1_{y_{i\ell}=v}} \prod_{v=1}^V B_{kv}^{\gamma_v-1} \right].
\end{align*}
The conjugacy should now be obvious, as well as the conditional independence of the rows of $B$. 
We see in particular that
$$
    B_{k:} \vert \mathbf{z}, \mathbf{y} \sim \mathrm{Dir}\left( (\gamma_v + \sum_{i=1}^N \sum_{\ell=1}^{L_i} 1_{z_{i\ell}=k}1_{y_{i\ell}=v})_{v\in [V]} \right).
$$

\paragraph{The conditional of $z_{i\ell}$}
Fix $i\in[N]$ and $\ell\in[L_i]$. 
Then by \eqref{e:conditional_independence} and the DAG structure,
$$
    z_{i\ell} \vert \mathbf{\pi}, \mathbf{z}_{\setminus i\ell}, \mathbf{y}, B \sim z_{i\ell} \vert \pi_i, y_{i\ell}, B.
$$
Using Bayes' theorem, we can again force terms to appear that we have specified in our model.
\begin{align*}
    p(z_{i\ell} = k \vert \pi_i, y_{i\ell}, B) 
    &\propto p(z_{i\ell} = k, \pi_i, y_{i\ell}, B)\\
    &= p(y_{i\ell}\vert z_{i\ell} = k, \pi_i, B) p(z_{i\ell} = k, B\vert\pi_i) p(\pi_i).
\end{align*}
Upong noting that $y_{i\ell}\perp \pi_i\vert z_{i\ell} = k,  B$ and $z_{i\ell} = k \perp B\vert\pi_i$, and keeping only terms that contain $z_{i\ell}$, it comes 
$$
    p(z_{i\ell} = k \vert \pi_i, y_{i\ell}, B) \propto p(y_{i\ell}\vert z_{i\ell} = k, B) p(z_{i\ell} = k \vert\pi_i) \propto B_{k y_{i\ell}} \pi_{ik}.
$$
To sample from the conditional of $z_{i\ell}$, it is thus enough to draw a new index $k\in[K]$ with probability 
$$
    \frac{B_{k y_{i\ell}} \pi_{ik}}{\sum_{k=1}^K B_{k y_{i\ell}} \pi_{ik}}.
$$

\section{Combining MCMC kernels}
Note that if $P_1$ and $P_2$ both leave $\pi$ invariant, then so does the compound kernel
$$
    P_1P_2(x, x') = \int P_1(x, \xi)P_2(\xi, x') \d\xi.
$$
In particular, one can apply two MH kernels with different proposals one after the other, and still get a valid kernel, in the sense that it leaves the same target invariant. 
Another basic example is the systematic scan Gibbs sampler; see exercise sheet.
Alternately, we can combine an MH and a Gibbs kernel, to use the fact that we can sample some of the components of the state conditionally on the others.

\begin{example}[Hierarchical logistic regression]
    TBC
\end{example}

Another famous example of compound kernel is Hamiltonian Monte Carlo.

\section{Hamiltonian Monte Carlo}
\label{s:HMC}

Check out Chi Feng's MCMC gallery\footnote{\url{https://chi-feng.github.io/mcmc-demo}}.
In particular, run MH and the Gibbs sampler on the banana-shaped Gaussian, and see how difficult it is for the corresponding chains to move along the banana. 
Intuitively, it would be more efficient to have an MCMC kernel that somehow follows the level lines of the target $\pi$. 
Inspired by numerical schemes for solving differential equations in mechanics, \cite{Nea00} introduced HMC, an MCMC kernel that approximately follows the level lines of an augmented target with marginal $\pi$.
The HMC kernel and its adaptive variants like NUTS are now the default choice in most probabilistic programming languages, such as PyMC and Stan.

While sometimes handwavingly introduced as an instance MH, we believe that the practical popularity of HMC justifies understanding it in its own right.
We closely follow \cite{BoSa18}; and temporarily adopt their notational conventions: the variable over which we wish to integrate is $q\in\mathbb{R}^d$, while $x\in\cX$ denotes a generic variable, later taken to be $x=(p,q)\in\mathbb{R}^{2d}$.
Note that vanilla HMC is limited to continuous variables.

\subsection{An abstract variant of Metropolis-Hastings}
\label{s:abstract_HMC}
Let $S$ be a linear involution of $\cX\subset\mathbb{R}^{2d}$, such that $\eta\circ S = \eta$ for some (possibly unnormalized) PDF $\eta$.
Let further $\Phi:\mathbb{R}^{2d}\rightarrow \mathbb{R}^{2d}$ be a $C^1$-diffeomorphism\footnote{
    While we prefer to keep $\Phi$ generic at this stage, you can intuitively think of $\Phi$ as moving along a level line of $\eta$.
} 
that is reversible w.r.t. to $S$, that is, $S\circ \Phi = \Phi^{-1}\circ S$.
Now let 
\begin{equation}
    \label{e:acceptance_probability_abstract_HMC}
    \alpha(x) \triangleq 1\wedge \frac{\eta(\Phi(x))}{\eta(x)} \vert\Phi'(x)\vert,
\end{equation}
and consider the Markov kernel
$$
P_{aHMC}(x,A) = \alpha(x) 1_{\Phi(x)\in A} + (1-\alpha(x))1_{S(x)\in A}.
$$
Algorithmically, this ``abstract" HMC kernel corresponds to accepting $\Phi(x)$ with probability $\alpha(x)$, and otherwise setting the new Markov state to $S(x)$.
\begin{proposition}
\label{p:invariance_abstract_HMC}
$P_{aHMC}$ leaves $\eta$ invariant.
\end{proposition}
\begin{proof}
    Left as an exercise.
\end{proof}

\subsection{An augmented target}
Consider the PDF on $\mathbb{R}^{2d}$ defined by $\tpi(q,p) = \frac12 \cN(p\vert 0, M) \times \pi(q)$. 
Clearly, the $p$-marginal is Gaussian, while the $q$-marginal is $\pi$. 
If we manage to obtain an MCMC chain for $\tpi$, i.e. a chain with a Markov kernel that leaves $\tpi$ invariant, then simply discarding the $p$-component of every realization will yield a chain that is invariant w.r.t. $\pi$. 
This is an example of \emph{augmentation} of the state space: unlike for the collapsed Gibbs sampling of Section~\ref{s:collapsed_gibbs}, we augment the dimensionality of the problem in the hope to make sampling easier. 
Our hope is justified here by the fact that we know how to efficiently move in $\mathbb{R}^{2d}$ along the level lines of the augmented density $\tpi$: this is were Hamiltonian dynamics come into play.

\subsection{Hamiltonian dynamics}
\label{s:hamiltonian_dynamics}
Let $H(q,p) = \log\tpi(q,p)$, and consider the differential equation 
\begin{equation}
    \label{e:differential_equation}
    \frac{\d}{\d t} \begin{pmatrix} x\\p \end{pmatrix} = J \nabla H(q,p), \quad\text{ where } J=\begin{pmatrix} 0_d & -I_d \\ I_d & 0_d \end{pmatrix}.
\end{equation} 
In particular, if $\nabla H$ is Lipschitz, which we shall always assume in this section, the Cauchy-Lipschitz theorem yields a unique solution to \eqref{e:differential_equation} passing through $(q_0,p_0)$ at $t=0$, which we denote by $t\mapsto \phi_t(q_0,p_0)$.
We shall further assume that $\phi_t$ is well defined for all $t$, and call $\phi_t$ the \emph{Hamiltonian flow}. 
By definition, the Hamiltonian flow preserves the Hamiltonian, since
$$
\frac{\d}{\d t} H(\phi_t(q_0,p_0)) = \nabla H(\phi_t(q_0,p_0))^T J \nabla H(\phi_t(q_0,p_0)) = 0,
$$
$J$ being skew-symmetric.
In other words, the flow $\phi_t$ follows level lines of $H$.

\subsection{Ideal HMC and numerical HMC}
The ideal HMC is the concatenation of two kernels. 
Given $(q_n,p_n)$, first resample $p$ from its conditional under $\tpi$; i.e. $p'\sim \cN(0,M)$. 
This obviously leaves $\tpi$ invariant, as in Gibbs sampling. 
Then set $(q_{n+1}, p_{n+1}) = \phi_T(q_n,p')$.
In words, one step of the corresponding Markov chain consists of sampling a random momentum variable from the corresponding conditional, and then following the Hamiltonian flow $\phi_t$ up to time $T>0$.
Note that, unlike Gibbs sampling, this second step changes both variables.

One can formulate the intuition that, since the second step just follows a level line of $H$, the ideal HMC kernel leaves $\tpi$ invariant. This is indeed the case \citep{BoSa18}, but since $\phi_t$ is usually not available in closed form, the ideal HMC kernel cannot be implemented, and we will skip the proof of its invariance. 

In practice, one has to approximate the Hamiltonian flow $\phi_t$, and there is a large literature in numerical analysis on the subject, with integrators showcasing many interesting properties.
In terms of notation, denote by $h$ a stepsize parameter, and $n=\lfloor T/h\rfloor$, so that we think of the numerical integrator $\psi_h^n(x,p)$ as an approximation to $\phi_T(x,p)$.
There exists numerical integrators $\phi_h^n$ that are $(i)$ $C^1$ diffeomorphisms, $(ii)$ are reversible w.r.t. to momentum flip, and are volume-preserving, i.e. $\vert \det (\psi_h^n)'(q,p)\vert = 1$.
Since the momentum flip preserves $\tpi$, we can replace the second step of the ideal HMC algorithm by the abstract HMC algorithm of Section~\ref{s:abstract_HMC}, with $\eta=\tpi$, $\Phi=\phi_h^n$ and $S$ the momentum flip. 
Because the numerical integrator is volume-preserving, the acceptance probability becomes suprisingly simple, as 
$$ 
\alpha_{HMC}((q,p),(q',p')) = 1\wedge \e^{-H(q,p)-H(q',p')}.
$$
Intuitively, the acceptance step compensates for the fact that we did not exactly follow the level lines of $H$. 

One common numerical integrator satisfying all the required properties is the leapfrog (aka velocity Verlet in \citep{BoSa18}) integrator defined as $\psi_h^n = \psi_h \circ \dots \psi_h$, where $(p',q') = \psi_h(p,q)$ is defined by
\begin{align*}
    p_{1/2} &= p + \frac{h}{2}\nabla \log \pi(q)\\
    q' &= a+hM^{-1}p_{1/2}\\
    p' &= p_{1/2} + \frac{h}{2} \nabla \log\pi (q');
\end{align*}
see \citep[Section 3]{BoSa18} for more information, and \cfdemo for an interactive demo.

\subsection{On the ergodicity of HMC}

\subsection{An ubiquitous variant: NUTS}
NUTS for auto-tuning, etc.

\section{MCMC practice: convergence diagnostics}
Convergence diagnostics. Discuss the output of pymc.

\section{Alternative methods}
\label{s:alternative_methods}

\subsection{Other randomized quadratures}
More kernels, SMC samplers, PDMPs

\subsection{Deterministic quadrature in large dimensions}
Herding
QMC, randomized QMC

