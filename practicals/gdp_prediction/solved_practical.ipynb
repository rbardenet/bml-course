{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting GDP as a function of a country's ruggedness\n",
    "This practical helps you answer a fictitious geographer's questions to you, the data scientist. This practical is based on a paper by [Nunn and Puga, Review of Economics and Statistics, 2012](https://diegopuga.org/research/rugged.pdf). Once you're done with the practical, check out the paper to see how the authors propose to explain the results of their statistical analysis. The solution of the practical is also avalaible at https://colab.research.google.com/drive/1jmhhnHWZ1ayGumizGV06bgZpHMdVd0mJ?usp=sharing ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the notebook reloads the module each time we modify it\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# make sure the displays are nice\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import solved_gdp_prediction as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import scipy.stats as sps\n",
    "import pymc3 as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I prepared a class that fetches data for you\n",
    "GP = gp.GDPPredictionUsingLinearRegression()\n",
    "X, y = GP.fetch_data()\n",
    "print(\"The dimensions of data are\", X.shape)\n",
    "\n",
    "# Data is normalized\n",
    "print(\"Mean and std of y are\", np.mean(y), np.std(y))\n",
    "\n",
    "# Let us plot data\n",
    "sns.scatterplot(X, y)\n",
    "plt.ylabel(\"log GDP\")\n",
    "plt.xlabel(\"Ruggedness index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you work for a geographer. She wants to test the hypothesis that the log GDP increases with ruggedness. You reply that without knowledge about how $X$ and $y$ relate, and only 170 points, it seems reasonable to stick to a simple model, say linear regression. \n",
    "\n",
    "**Question:** Assuming you perform a linear regression of the log GDP onto the ruggedness index, how will you formalize the test that the geographer is asking for? In other words, what are the states, actions, loss function, and Bayes action? What quantity should you report to the geographer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** As Bayesians, we need a distribution over states, a set of actions, and and a loss function.\n",
    "1. Linear regression and a choice of prior will give us a joint distribution $\\pi$ over states $s=(X, \\mathbf{y}, \\theta)$, where $\\theta=(\\alpha,\\beta,\\sigma)$, $y_i=\\alpha+\\beta x_i+\\epsilon_i$, and, for example, $\\epsilon_i\\sim\\mathcal{N}(0,\\sigma^2)$ i.i.d. \n",
    "2. Actions are naturally indexed by predictors for the sign of $\\beta$. Let $\\mathcal G$ be the set of measurable functions that map values of $X,\\mathbf y$ to $\\{0,1\\}$, where we think of a prediction of $1$ as predicting that $\\beta>0$. Then, if we take\n",
    "$$\n",
    "\\mathcal A = \\{a_g: s\\mapsto (1_{\\beta>0}, g(X,y)), g\\in \\mathcal G \\},\n",
    "$$\n",
    "we shall be able to model type I and type II errors. \n",
    "The geographer should tell us how much she would suffer if we answered yes/no and the state was $s$. This gives us costs $\\ell_1, \\ell_2>0$. We can then take\n",
    "$$\n",
    "L(a,s) = \\ell_1 1_{\\beta>0} \\times (1-g(X,\\mathbf y)) + \\ell_2 1_{\\beta\\leq 0} \\times g(X,\\mathbf y).\n",
    "$$\n",
    "Like in asymmetric classification (see exercise sheet), the Bayes action is then to set $g^*(X,\\mathbf y) = 1 $ if and only if\n",
    "$$ \n",
    "\\pi(\\beta>0\\vert X,\\mathbf{y}) > \\frac{\\ell_2}{\\ell_1+\\ell_2}.\n",
    "$$\n",
    "The quantity to report to the geographer is thus $\\pi(\\beta>0\\vert X,\\mathbf{y})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** First write down your model (likelihood and prior).\n",
    "\n",
    "**Solution:**\n",
    "* The likelihood is $p(\\mathbf{y}\\vert X, \\theta) = \\prod_{i=1}^n \\mathcal{N}(y_i\\vert \\alpha+\\beta x_i, \\sigma^2)$.\n",
    "* The simplest prior is $p(\\theta) = p(\\alpha,\\beta,\\log\\sigma) = \\mathcal{N}((0,0,0),I)$, in which case we actually know the posterior in closed form; see Lecture #1. We shall also distributions with fatter tails, like a Student or a Cauchy, in which case we genuinely need numerical integration.\n",
    "* The posterior is proportional to \n",
    "$$ p(\\theta\\vert X,y) \\propto p(\\mathbf{y}\\vert X, \\theta)p(\\theta).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Now use PyMC to code your model in the companion Python file, within method `get_mcmc_sample` of class `GDPPredictionUsingLinearRegression.`and method . Then run the default MCMC sampler (HMC with NUTS, we shall cover it in the next lecture). If your syntax is correct, you should be able to run the following cells to visualize the results. Comment on the realization of your chain. What is the `Rhat` column in the summary of the trace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = GP.get_mcmc_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace, show=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Now turn your chain into an estimator of $\\pi(\\beta>0\\vert X, \\mathbf{y})$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_traces = trace['beta']\n",
    "plt.hist(beta_traces)\n",
    "plt.show()\n",
    "print(\"Our estimate of the posterior probability of beta>0 is\", np.mean(beta_traces>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** \n",
    "* If $\\ell_1=\\ell_2$, it's a close call: if you resample your chain and or change your prior, you'll see that our estimator has a standard deviation of the order of the difference between its mean and $1/2$. Depending on the realization of your MCMC chain and you choice of prior, you will thus recommend a different action, and it might not be the underlying Bayes action. This means that we need more MCMC iterations to reduce MC error, or more data, or a different model/prior.\n",
    "* If $\\ell_1 = 2\\ell_2$, for instance, then we are confident that $\\pi(\\beta>0\\vert X, \\mathbf{y})>1/3$ and the Bayes action is to conclude that $\\beta>0$.\n",
    "* If $\\ell_2 = 2\\ell_1$, for instance, then we are confident that $\\pi(\\beta>0\\vert X, \\mathbf{y})<2/3$ and the Bayes action is to conclude that $\\beta<0$. In particular, see how our final decision depends on the loss function, not only on the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A hierarchical linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same geographer comes back to you. She has a new hypothesis: GDP only increases with ruggedness for African nations. We have the same 170 points, with $y_i$ the log GDP, and $x_i$ the ruggedness index, for $i=1,\\dots,170$. But now we also have a new binary variable $z_i\\in\\{0,1\\}$, $i=1,\\dots,170$, that indicates whether the corresponding country is in Africa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I prepared a new class that fetches data for you\n",
    "HM = gp.GDPPredictionUsingHierarchicalRegression()\n",
    "X, y = HM.fetch_data()\n",
    "\n",
    "# Let us plot data\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "sns.scatterplot(X[\"rest\"], y[\"rest\"], ax=ax[0])\n",
    "ax[0].set(xlabel=\"Ruggedness index\", ylabel=\"log GDP\", title=\"Non-African nations\")\n",
    "\n",
    "sns.scatterplot(X[\"African\"], y[\"African\"], ax=ax[1])\n",
    "ax[1].set(xlabel=\"Ruggedness index\", ylabel=\"log GDP\", title=\"African nations\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we want to examine a potential difference between the parameters corresponding to African and non-African countries. We thus come up with a hierarchical model \n",
    "* $y_{\\circ,i}=\\alpha_\\circ+\\beta_\\circ x_i+\\epsilon_{\\circ,i}$, where $\\epsilon_{\\circ,i}$ are i.i.d. $ \\mathcal{N}(0,\\sigma_\\circ^2)$ and $\\circ\\in\\{\\text{African}, \\text{rest}\\}$,\n",
    "* $\\alpha_{\\text{African}}, \\alpha_{\\text{rest}} \\sim p(\\cdot \\vert \\alpha)$ i.i.d., with some prior on the common $\\alpha$. Same for $\\beta_\\circ, \\sigma_\\circ$ and $\\beta, \\sigma$. In total, we know have 9 parameters: three per class, and three common ones.\n",
    "\n",
    "Go to class `GDPPredictionUsingHierarchicalRegression` and fill in the method `get_mcmc_sample` with your model. Make simple choices for priors, and make sure to later check that your decision does not depend on your choices. Run your MCMC sampler and examine the output of your chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_hierarchical = HM.get_mcmc_sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace_hierarchical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the HPD credible interval for $\\beta_\\text{African}$ has shifted to the right compared to the non-hierarchical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace_hierarchical)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a strong difference between the posterior marginals of beta_African and beta_rest. \n",
    "# Meanwhile the posterior on their common mean beta is quite uninformative.\n",
    "plt.hist(trace_hierarchical['beta_African'], label=\"African\")\n",
    "plt.hist(trace_hierarchical['beta_rest'], label=\"rest\")\n",
    "plt.hist(trace_hierarchical['beta'], alpha=.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** what do we conlude and tell the geographer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we estimate the posterior of beta_African being positive\n",
    "print(np.mean(trace_hierarchical['beta_African']>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** This time, unless the ratio $\\ell_1/\\ell_2$ is extreme, we will conclude that indeed, the GDP of African countries increases with ruggedness. Run your chain again with different priors and check that this decision is robust to prior changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus question:** The geographer asks you for a prediction of the GDP of an African country with ruggedness $4$, what do you say?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** It is again a decision problem. As seen in course, if your loss for the prediction is $L^2$, then the Bayes answer is the mean of the posterior predictive. If the geographer prefer an interval, you can report a credible interval, i.e. an interval with posterior predictive mass larger than a given threshold, say $95\\%$. In any case, you need to use your chain to estimate the corresponding prediction or interval. Below I plot the estimated posterior predictive in the form of a sample. To find the credible interval corresponding to a ruggedness of 4, simply draw a vertical line at abscissa 4, and report an interbal containing 95% of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(X[\"African\"], y[\"African\"])\n",
    "plt.ylabel(\"log GDP\")\n",
    "plt.xlabel(\"Ruggedness index\")\n",
    "t = trace_hierarchical\n",
    "lag = 100\n",
    "for a, b in zip(t[\"alpha_African\"][::lag], t[\"beta_African\"][::lag]):\n",
    "    plt.plot(X[\"African\"], a + b*X[\"African\"], color=\"orange\", alpha=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
